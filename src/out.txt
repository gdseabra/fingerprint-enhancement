[[36m2025-05-22 19:07:19,969[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2025-05-22 19:07:19,973[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.enhancer_train_datamodule.EnhancerTrainDataModule                                                        
â”‚       data_dir: /storage/gabriel/basen_train//                                                                                    
â”‚       data_list: masks_ref_list.txt                                                                                               
â”‚       lat_subdir: /lat_synthetic_documents/                                                                                       
â”‚       ref_subdir: /ref_orig/                                                                                                      
â”‚       skel_subdir: /ref_skel/                                                                                                     
â”‚       mask_subdir: /masks_synthetic_bg/                                                                                           
â”‚       mnt_map_subdir: /ref_mnt_map/                                                                                               
â”‚       apply_mask: 0                                                                                                               
â”‚       batch_size: 32                                                                                                              
â”‚       train_val_split:                                                                                                            
â”‚       - 0.7                                                                                                                       
â”‚       - 0.3                                                                                                                       
â”‚       num_workers: 8                                                                                                              
â”‚       pin_memory: false                                                                                                           
â”‚                                                                                                                                   
â”œâ”€â”€ model
â”‚   â””â”€â”€ _target_: src.models.enhancer_module.EnhancerLitModule                                                                      
â”‚       optimizer:                                                                                                                  
â”‚         _target_: torch.optim.AdamW                                                                                               
â”‚         _partial_: true                                                                                                           
â”‚         lr: 0.0001                                                                                                                
â”‚         weight_decay: 0.0001                                                                                                      
â”‚       scheduler:                                                                                                                  
â”‚         _target_: torch.optim.lr_scheduler.ReduceLROnPlateau                                                                      
â”‚         _partial_: true                                                                                                           
â”‚         mode: min                                                                                                                 
â”‚         factor: 0.1                                                                                                               
â”‚         patience: 2                                                                                                               
â”‚       net:                                                                                                                        
â”‚         _target_: src.models.components.ResUNet.ResUNet                                                                           
â”‚         in_ch: 1                                                                                                                  
â”‚         chs:                                                                                                                      
â”‚         - 64                                                                                                                      
â”‚         - 128                                                                                                                     
â”‚         - 256                                                                                                                     
â”‚         - 512                                                                                                                     
â”‚         - 1024                                                                                                                    
â”‚         ndim: 2                                                                                                                   
â”‚         out_ch: 1                                                                                                                 
â”‚       compile: false                                                                                                              
â”‚       output_path: /home/gabriel/fingerprint-enhancement/output/                                                                  
â”‚                                                                                                                                   
â”œâ”€â”€ callbacks
â”‚   â””â”€â”€ model_checkpoint:                                                                                                           
â”‚         _target_: lightning.pytorch.callbacks.ModelCheckpoint                                                                     
â”‚         dirpath: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-05-22_19-07-19/checkpoints                            
â”‚         filename: epoch_{epoch:03d}                                                                                               
â”‚         monitor: val/loss_best                                                                                                    
â”‚         verbose: false                                                                                                            
â”‚         save_last: true                                                                                                           
â”‚         save_top_k: 1                                                                                                             
â”‚         mode: min                                                                                                                 
â”‚         auto_insert_metric_name: false                                                                                            
â”‚         save_weights_only: false                                                                                                  
â”‚         every_n_train_steps: null                                                                                                 
â”‚         train_time_interval: null                                                                                                 
â”‚         every_n_epochs: null                                                                                                      
â”‚         save_on_train_epoch_end: null                                                                                             
â”‚       early_stopping:                                                                                                             
â”‚         _target_: lightning.pytorch.callbacks.EarlyStopping                                                                       
â”‚         monitor: val/loss_best                                                                                                    
â”‚         min_delta: 0.0                                                                                                            
â”‚         patience: 5                                                                                                               
â”‚         verbose: false                                                                                                            
â”‚         mode: min                                                                                                                 
â”‚         strict: true                                                                                                              
â”‚         check_finite: true                                                                                                        
â”‚         stopping_threshold: null                                                                                                  
â”‚         divergence_threshold: null                                                                                                
â”‚         check_on_train_epoch_end: null                                                                                            
â”‚       model_summary:                                                                                                              
â”‚         _target_: lightning.pytorch.callbacks.RichModelSummary                                                                    
â”‚         max_depth: -1                                                                                                             
â”‚       rich_progress_bar:                                                                                                          
â”‚         _target_: lightning.pytorch.callbacks.RichProgressBar                                                                     
â”‚                                                                                                                                   
â”œâ”€â”€ logger
â”‚   â””â”€â”€ mlflow:                                                                                                                     
â”‚         _target_: lightning.pytorch.loggers.mlflow.MLFlowLogger                                                                   
â”‚         experiment_name: fingerprint enhancer                                                                                     
â”‚         tracking_uri: /home/gabriel/fingerprint-enhancement/logs//mlflow/mlruns                                                   
â”‚         tags: null                                                                                                                
â”‚         prefix: ''                                                                                                                
â”‚         artifact_location: null                                                                                                   
â”‚                                                                                                                                   
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: lightning.pytorch.trainer.Trainer                                                                                 
â”‚       default_root_dir: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-05-22_19-07-19                                 
â”‚       min_epochs: 1                                                                                                               
â”‚       max_epochs: 300                                                                                                             
â”‚       accelerator: gpu                                                                                                            
â”‚       devices: 4                                                                                                                  
â”‚       check_val_every_n_epoch: 1                                                                                                  
â”‚       deterministic: false                                                                                                        
â”‚                                                                                                                                   
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /home/gabriel/fingerprint-enhancement                                                                             
â”‚       data_dir: /storage/gabriel/basen_train/                                                                                     
â”‚       log_dir: /home/gabriel/fingerprint-enhancement/logs/                                                                        
â”‚       output_dir: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-05-22_19-07-19                                       
â”‚       work_dir: /home/gabriel/fingerprint-enhancement/src                                                                         
â”‚                                                                                                                                   
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                                                                      
â”‚       enforce_tags: true                                                                                                          
â”‚       print_config: true                                                                                                          
â”‚                                                                                                                                   
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ train                                                                                                                       
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['dev']                                                                                                                     
â”œâ”€â”€ train
â”‚   â””â”€â”€ True                                                                                                                        
â”œâ”€â”€ test
â”‚   â””â”€â”€ False                                                                                                                       
â”œâ”€â”€ ckpt_path
â”‚   â””â”€â”€ /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-05-18_04-36-05/checkpoints/last.ckpt                             
â””â”€â”€ seed
    â””â”€â”€ None                                                                                                                        
[[36m2025-05-22 19:07:20,014[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.enhancer_train_datamodule.EnhancerTrainDataModule>[0m
[[36m2025-05-22 19:07:20,018[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.enhancer_module.EnhancerLitModule>[0m
[[36m2025-05-22 19:07:21,821[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2025-05-22 19:07:21,822[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-22 19:07:21,827[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2025-05-22 19:07:21,828[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-22 19:07:21,829[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-22 19:07:21,829[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2025-05-22 19:07:21,830[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.mlflow.MLFlowLogger>[0m
[[36m2025-05-22 19:07:21,834[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-22 19:07:21,889[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
[[36m2025-05-22 19:07:21,964[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ     â”ƒ Name                                 â”ƒ Type        â”ƒ Params â”ƒ Mode  â”ƒ
â”¡â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ 0   â”‚ net                                  â”‚ ResUNet     â”‚ 30.3 M â”‚ train â”‚
â”‚ 1   â”‚ net.encoder                          â”‚ Encoder     â”‚ 19.5 M â”‚ train â”‚
â”‚ 2   â”‚ net.encoder.enc_blocks               â”‚ ModuleList  â”‚ 19.5 M â”‚ train â”‚
â”‚ 3   â”‚ net.encoder.enc_blocks.0             â”‚ ResnetBlock â”‚ 38.0 K â”‚ train â”‚
â”‚ 4   â”‚ net.encoder.enc_blocks.0.block1      â”‚ Block       â”‚    768 â”‚ train â”‚
â”‚ 5   â”‚ net.encoder.enc_blocks.0.block1.proj â”‚ Conv2d      â”‚    640 â”‚ train â”‚
â”‚ 6   â”‚ net.encoder.enc_blocks.0.block1.norm â”‚ GroupNorm   â”‚    128 â”‚ train â”‚
â”‚ 7   â”‚ net.encoder.enc_blocks.0.block1.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 8   â”‚ net.encoder.enc_blocks.0.block2      â”‚ Block       â”‚ 37.1 K â”‚ train â”‚
â”‚ 9   â”‚ net.encoder.enc_blocks.0.block2.proj â”‚ Conv2d      â”‚ 36.9 K â”‚ train â”‚
â”‚ 10  â”‚ net.encoder.enc_blocks.0.block2.norm â”‚ GroupNorm   â”‚    128 â”‚ train â”‚
â”‚ 11  â”‚ net.encoder.enc_blocks.0.block2.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 12  â”‚ net.encoder.enc_blocks.0.res_conv    â”‚ Conv2d      â”‚    128 â”‚ train â”‚
â”‚ 13  â”‚ net.encoder.enc_blocks.1             â”‚ ResnetBlock â”‚  230 K â”‚ train â”‚
â”‚ 14  â”‚ net.encoder.enc_blocks.1.block1      â”‚ Block       â”‚ 74.1 K â”‚ train â”‚
â”‚ 15  â”‚ net.encoder.enc_blocks.1.block1.proj â”‚ Conv2d      â”‚ 73.9 K â”‚ train â”‚
â”‚ 16  â”‚ net.encoder.enc_blocks.1.block1.norm â”‚ GroupNorm   â”‚    256 â”‚ train â”‚
â”‚ 17  â”‚ net.encoder.enc_blocks.1.block1.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 18  â”‚ net.encoder.enc_blocks.1.block2      â”‚ Block       â”‚  147 K â”‚ train â”‚
â”‚ 19  â”‚ net.encoder.enc_blocks.1.block2.proj â”‚ Conv2d      â”‚  147 K â”‚ train â”‚
â”‚ 20  â”‚ net.encoder.enc_blocks.1.block2.norm â”‚ GroupNorm   â”‚    256 â”‚ train â”‚
â”‚ 21  â”‚ net.encoder.enc_blocks.1.block2.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 22  â”‚ net.encoder.enc_blocks.1.res_conv    â”‚ Conv2d      â”‚  8.3 K â”‚ train â”‚
â”‚ 23  â”‚ net.encoder.enc_blocks.2             â”‚ ResnetBlock â”‚  919 K â”‚ train â”‚
â”‚ 24  â”‚ net.encoder.enc_blocks.2.block1      â”‚ Block       â”‚  295 K â”‚ train â”‚
â”‚ 25  â”‚ net.encoder.enc_blocks.2.block1.proj â”‚ Conv2d      â”‚  295 K â”‚ train â”‚
â”‚ 26  â”‚ net.encoder.enc_blocks.2.block1.norm â”‚ GroupNorm   â”‚    512 â”‚ train â”‚
â”‚ 27  â”‚ net.encoder.enc_blocks.2.block1.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 28  â”‚ net.encoder.enc_blocks.2.block2      â”‚ Block       â”‚  590 K â”‚ train â”‚
â”‚ 29  â”‚ net.encoder.enc_blocks.2.block2.proj â”‚ Conv2d      â”‚  590 K â”‚ train â”‚
â”‚ 30  â”‚ net.encoder.enc_blocks.2.block2.norm â”‚ GroupNorm   â”‚    512 â”‚ train â”‚
â”‚ 31  â”‚ net.encoder.enc_blocks.2.block2.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 32  â”‚ net.encoder.enc_blocks.2.res_conv    â”‚ Conv2d      â”‚ 33.0 K â”‚ train â”‚
â”‚ 33  â”‚ net.encoder.enc_blocks.3             â”‚ ResnetBlock â”‚  3.7 M â”‚ train â”‚
â”‚ 34  â”‚ net.encoder.enc_blocks.3.block1      â”‚ Block       â”‚  1.2 M â”‚ train â”‚
â”‚ 35  â”‚ net.encoder.enc_blocks.3.block1.proj â”‚ Conv2d      â”‚  1.2 M â”‚ train â”‚
â”‚ 36  â”‚ net.encoder.enc_blocks.3.block1.norm â”‚ GroupNorm   â”‚  1.0 K â”‚ train â”‚
â”‚ 37  â”‚ net.encoder.enc_blocks.3.block1.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 38  â”‚ net.encoder.enc_blocks.3.block2      â”‚ Block       â”‚  2.4 M â”‚ train â”‚
â”‚ 39  â”‚ net.encoder.enc_blocks.3.block2.proj â”‚ Conv2d      â”‚  2.4 M â”‚ train â”‚
â”‚ 40  â”‚ net.encoder.enc_blocks.3.block2.norm â”‚ GroupNorm   â”‚  1.0 K â”‚ train â”‚
â”‚ 41  â”‚ net.encoder.enc_blocks.3.block2.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 42  â”‚ net.encoder.enc_blocks.3.res_conv    â”‚ Conv2d      â”‚  131 K â”‚ train â”‚
â”‚ 43  â”‚ net.encoder.enc_blocks.4             â”‚ ResnetBlock â”‚ 14.7 M â”‚ train â”‚
â”‚ 44  â”‚ net.encoder.enc_blocks.4.block1      â”‚ Block       â”‚  4.7 M â”‚ train â”‚
â”‚ 45  â”‚ net.encoder.enc_blocks.4.block1.proj â”‚ Conv2d      â”‚  4.7 M â”‚ train â”‚
â”‚ 46  â”‚ net.encoder.enc_blocks.4.block1.norm â”‚ GroupNorm   â”‚  2.0 K â”‚ train â”‚
â”‚ 47  â”‚ net.encoder.enc_blocks.4.block1.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 48  â”‚ net.encoder.enc_blocks.4.block2      â”‚ Block       â”‚  9.4 M â”‚ train â”‚
â”‚ 49  â”‚ net.encoder.enc_blocks.4.block2.proj â”‚ Conv2d      â”‚  9.4 M â”‚ train â”‚
â”‚ 50  â”‚ net.encoder.enc_blocks.4.block2.norm â”‚ GroupNorm   â”‚  2.0 K â”‚ train â”‚
â”‚ 51  â”‚ net.encoder.enc_blocks.4.block2.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 52  â”‚ net.encoder.enc_blocks.4.res_conv    â”‚ Conv2d      â”‚  525 K â”‚ train â”‚
â”‚ 53  â”‚ net.encoder.pool                     â”‚ MaxPool2d   â”‚      0 â”‚ train â”‚
â”‚ 54  â”‚ net.decoder                          â”‚ Decoder     â”‚ 10.8 M â”‚ train â”‚
â”‚ 55  â”‚ net.decoder.upconvs                  â”‚ ModuleList  â”‚  697 K â”‚ train â”‚
â”‚ 56  â”‚ net.decoder.upconvs.0                â”‚ Sequential  â”‚  524 K â”‚ train â”‚
â”‚ 57  â”‚ net.decoder.upconvs.0.0              â”‚ Upsample    â”‚      0 â”‚ train â”‚
â”‚ 58  â”‚ net.decoder.upconvs.0.1              â”‚ Conv2d      â”‚  524 K â”‚ train â”‚
â”‚ 59  â”‚ net.decoder.upconvs.1                â”‚ Sequential  â”‚  131 K â”‚ train â”‚
â”‚ 60  â”‚ net.decoder.upconvs.1.0              â”‚ Upsample    â”‚      0 â”‚ train â”‚
â”‚ 61  â”‚ net.decoder.upconvs.1.1              â”‚ Conv2d      â”‚  131 K â”‚ train â”‚
â”‚ 62  â”‚ net.decoder.upconvs.2                â”‚ Sequential  â”‚ 32.9 K â”‚ train â”‚
â”‚ 63  â”‚ net.decoder.upconvs.2.0              â”‚ Upsample    â”‚      0 â”‚ train â”‚
â”‚ 64  â”‚ net.decoder.upconvs.2.1              â”‚ Conv2d      â”‚ 32.9 K â”‚ train â”‚
â”‚ 65  â”‚ net.decoder.upconvs.3                â”‚ Sequential  â”‚  8.3 K â”‚ train â”‚
â”‚ 66  â”‚ net.decoder.upconvs.3.0              â”‚ Upsample    â”‚      0 â”‚ train â”‚
â”‚ 67  â”‚ net.decoder.upconvs.3.1              â”‚ Conv2d      â”‚  8.3 K â”‚ train â”‚
â”‚ 68  â”‚ net.decoder.dec_blocks               â”‚ ModuleList  â”‚ 10.1 M â”‚ train â”‚
â”‚ 69  â”‚ net.decoder.dec_blocks.0             â”‚ ResnetBlock â”‚  7.6 M â”‚ train â”‚
â”‚ 70  â”‚ net.decoder.dec_blocks.0.block1      â”‚ Block       â”‚  4.7 M â”‚ train â”‚
â”‚ 71  â”‚ net.decoder.dec_blocks.0.block1.proj â”‚ Conv2d      â”‚  4.7 M â”‚ train â”‚
â”‚ 72  â”‚ net.decoder.dec_blocks.0.block1.norm â”‚ GroupNorm   â”‚  1.0 K â”‚ train â”‚
â”‚ 73  â”‚ net.decoder.dec_blocks.0.block1.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 74  â”‚ net.decoder.dec_blocks.0.block2      â”‚ Block       â”‚  2.4 M â”‚ train â”‚
â”‚ 75  â”‚ net.decoder.dec_blocks.0.block2.proj â”‚ Conv2d      â”‚  2.4 M â”‚ train â”‚
â”‚ 76  â”‚ net.decoder.dec_blocks.0.block2.norm â”‚ GroupNorm   â”‚  1.0 K â”‚ train â”‚
â”‚ 77  â”‚ net.decoder.dec_blocks.0.block2.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 78  â”‚ net.decoder.dec_blocks.0.res_conv    â”‚ Conv2d      â”‚  524 K â”‚ train â”‚
â”‚ 79  â”‚ net.decoder.dec_blocks.1             â”‚ ResnetBlock â”‚  1.9 M â”‚ train â”‚
â”‚ 80  â”‚ net.decoder.dec_blocks.1.block1      â”‚ Block       â”‚  1.2 M â”‚ train â”‚
â”‚ 81  â”‚ net.decoder.dec_blocks.1.block1.proj â”‚ Conv2d      â”‚  1.2 M â”‚ train â”‚
â”‚ 82  â”‚ net.decoder.dec_blocks.1.block1.norm â”‚ GroupNorm   â”‚    512 â”‚ train â”‚
â”‚ 83  â”‚ net.decoder.dec_blocks.1.block1.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 84  â”‚ net.decoder.dec_blocks.1.block2      â”‚ Block       â”‚  590 K â”‚ train â”‚
â”‚ 85  â”‚ net.decoder.dec_blocks.1.block2.proj â”‚ Conv2d      â”‚  590 K â”‚ train â”‚
â”‚ 86  â”‚ net.decoder.dec_blocks.1.block2.norm â”‚ GroupNorm   â”‚    512 â”‚ train â”‚
â”‚ 87  â”‚ net.decoder.dec_blocks.1.block2.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 88  â”‚ net.decoder.dec_blocks.1.res_conv    â”‚ Conv2d      â”‚  131 K â”‚ train â”‚
â”‚ 89  â”‚ net.decoder.dec_blocks.2             â”‚ ResnetBlock â”‚  476 K â”‚ train â”‚
â”‚ 90  â”‚ net.decoder.dec_blocks.2.block1      â”‚ Block       â”‚  295 K â”‚ train â”‚
â”‚ 91  â”‚ net.decoder.dec_blocks.2.block1.proj â”‚ Conv2d      â”‚  295 K â”‚ train â”‚
â”‚ 92  â”‚ net.decoder.dec_blocks.2.block1.norm â”‚ GroupNorm   â”‚    256 â”‚ train â”‚
â”‚ 93  â”‚ net.decoder.dec_blocks.2.block1.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 94  â”‚ net.decoder.dec_blocks.2.block2      â”‚ Block       â”‚  147 K â”‚ train â”‚
â”‚ 95  â”‚ net.decoder.dec_blocks.2.block2.proj â”‚ Conv2d      â”‚  147 K â”‚ train â”‚
â”‚ 96  â”‚ net.decoder.dec_blocks.2.block2.norm â”‚ GroupNorm   â”‚    256 â”‚ train â”‚
â”‚ 97  â”‚ net.decoder.dec_blocks.2.block2.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 98  â”‚ net.decoder.dec_blocks.2.res_conv    â”‚ Conv2d      â”‚ 32.9 K â”‚ train â”‚
â”‚ 99  â”‚ net.decoder.dec_blocks.3             â”‚ ResnetBlock â”‚  119 K â”‚ train â”‚
â”‚ 100 â”‚ net.decoder.dec_blocks.3.block1      â”‚ Block       â”‚ 73.9 K â”‚ train â”‚
â”‚ 101 â”‚ net.decoder.dec_blocks.3.block1.proj â”‚ Conv2d      â”‚ 73.8 K â”‚ train â”‚
â”‚ 102 â”‚ net.decoder.dec_blocks.3.block1.norm â”‚ GroupNorm   â”‚    128 â”‚ train â”‚
â”‚ 103 â”‚ net.decoder.dec_blocks.3.block1.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 104 â”‚ net.decoder.dec_blocks.3.block2      â”‚ Block       â”‚ 37.1 K â”‚ train â”‚
â”‚ 105 â”‚ net.decoder.dec_blocks.3.block2.proj â”‚ Conv2d      â”‚ 36.9 K â”‚ train â”‚
â”‚ 106 â”‚ net.decoder.dec_blocks.3.block2.norm â”‚ GroupNorm   â”‚    128 â”‚ train â”‚
â”‚ 107 â”‚ net.decoder.dec_blocks.3.block2.act  â”‚ SiLU        â”‚      0 â”‚ train â”‚
â”‚ 108 â”‚ net.decoder.dec_blocks.3.res_conv    â”‚ Conv2d      â”‚  8.3 K â”‚ train â”‚
â”‚ 109 â”‚ net.head                             â”‚ Conv2d      â”‚     65 â”‚ train â”‚
â”‚ 110 â”‚ criterion                            â”‚ MyCriterion â”‚      0 â”‚ train â”‚
â”‚ 111 â”‚ train_loss                           â”‚ MeanMetric  â”‚      0 â”‚ train â”‚
â”‚ 112 â”‚ val_loss                             â”‚ MeanMetric  â”‚      0 â”‚ train â”‚
â”‚ 113 â”‚ test_loss                            â”‚ MeanMetric  â”‚      0 â”‚ train â”‚
â”‚ 114 â”‚ val_loss_best                        â”‚ MinMetric   â”‚      0 â”‚ train â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 30.3 M                                                                                                            
Non-trainable params: 0                                                                                                             
Total params: 30.3 M                                                                                                                
Total estimated model params size (MB): 121                                                                                         
Modules in train mode: 115                                                                                                          
Modules in eval mode: 0                                                                                                             
torch.Size([512, 512])
Epoch 100/299 â”â”â”                                      273/3163 0:01:00 â€¢ 0:10:33 4.57it/s v_num: 8ca4 train/loss_step: 320.044
torch.Size([512, 512])
torch.Size([512, 512])
torch.Size([512, 512])
[[36m2025-05-22 19:08:33,442[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Output dir: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-05-22_19-07-19[0m
