[[36m2025-05-22 19:07:19,969[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2025-05-22 19:07:19,973[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
├── data
│   └── _target_: src.data.enhancer_train_datamodule.EnhancerTrainDataModule                                                        
│       data_dir: /storage/gabriel/basen_train//                                                                                    
│       data_list: masks_ref_list.txt                                                                                               
│       lat_subdir: /lat_synthetic_documents/                                                                                       
│       ref_subdir: /ref_orig/                                                                                                      
│       skel_subdir: /ref_skel/                                                                                                     
│       mask_subdir: /masks_synthetic_bg/                                                                                           
│       mnt_map_subdir: /ref_mnt_map/                                                                                               
│       apply_mask: 0                                                                                                               
│       batch_size: 32                                                                                                              
│       train_val_split:                                                                                                            
│       - 0.7                                                                                                                       
│       - 0.3                                                                                                                       
│       num_workers: 8                                                                                                              
│       pin_memory: false                                                                                                           
│                                                                                                                                   
├── model
│   └── _target_: src.models.enhancer_module.EnhancerLitModule                                                                      
│       optimizer:                                                                                                                  
│         _target_: torch.optim.AdamW                                                                                               
│         _partial_: true                                                                                                           
│         lr: 0.0001                                                                                                                
│         weight_decay: 0.0001                                                                                                      
│       scheduler:                                                                                                                  
│         _target_: torch.optim.lr_scheduler.ReduceLROnPlateau                                                                      
│         _partial_: true                                                                                                           
│         mode: min                                                                                                                 
│         factor: 0.1                                                                                                               
│         patience: 2                                                                                                               
│       net:                                                                                                                        
│         _target_: src.models.components.ResUNet.ResUNet                                                                           
│         in_ch: 1                                                                                                                  
│         chs:                                                                                                                      
│         - 64                                                                                                                      
│         - 128                                                                                                                     
│         - 256                                                                                                                     
│         - 512                                                                                                                     
│         - 1024                                                                                                                    
│         ndim: 2                                                                                                                   
│         out_ch: 1                                                                                                                 
│       compile: false                                                                                                              
│       output_path: /home/gabriel/fingerprint-enhancement/output/                                                                  
│                                                                                                                                   
├── callbacks
│   └── model_checkpoint:                                                                                                           
│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                                                                     
│         dirpath: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-05-22_19-07-19/checkpoints                            
│         filename: epoch_{epoch:03d}                                                                                               
│         monitor: val/loss_best                                                                                                    
│         verbose: false                                                                                                            
│         save_last: true                                                                                                           
│         save_top_k: 1                                                                                                             
│         mode: min                                                                                                                 
│         auto_insert_metric_name: false                                                                                            
│         save_weights_only: false                                                                                                  
│         every_n_train_steps: null                                                                                                 
│         train_time_interval: null                                                                                                 
│         every_n_epochs: null                                                                                                      
│         save_on_train_epoch_end: null                                                                                             
│       early_stopping:                                                                                                             
│         _target_: lightning.pytorch.callbacks.EarlyStopping                                                                       
│         monitor: val/loss_best                                                                                                    
│         min_delta: 0.0                                                                                                            
│         patience: 5                                                                                                               
│         verbose: false                                                                                                            
│         mode: min                                                                                                                 
│         strict: true                                                                                                              
│         check_finite: true                                                                                                        
│         stopping_threshold: null                                                                                                  
│         divergence_threshold: null                                                                                                
│         check_on_train_epoch_end: null                                                                                            
│       model_summary:                                                                                                              
│         _target_: lightning.pytorch.callbacks.RichModelSummary                                                                    
│         max_depth: -1                                                                                                             
│       rich_progress_bar:                                                                                                          
│         _target_: lightning.pytorch.callbacks.RichProgressBar                                                                     
│                                                                                                                                   
├── logger
│   └── mlflow:                                                                                                                     
│         _target_: lightning.pytorch.loggers.mlflow.MLFlowLogger                                                                   
│         experiment_name: fingerprint enhancer                                                                                     
│         tracking_uri: /home/gabriel/fingerprint-enhancement/logs//mlflow/mlruns                                                   
│         tags: null                                                                                                                
│         prefix: ''                                                                                                                
│         artifact_location: null                                                                                                   
│                                                                                                                                   
├── trainer
│   └── _target_: lightning.pytorch.trainer.Trainer                                                                                 
│       default_root_dir: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-05-22_19-07-19                                 
│       min_epochs: 1                                                                                                               
│       max_epochs: 300                                                                                                             
│       accelerator: gpu                                                                                                            
│       devices: 4                                                                                                                  
│       check_val_every_n_epoch: 1                                                                                                  
│       deterministic: false                                                                                                        
│                                                                                                                                   
├── paths
│   └── root_dir: /home/gabriel/fingerprint-enhancement                                                                             
│       data_dir: /storage/gabriel/basen_train/                                                                                     
│       log_dir: /home/gabriel/fingerprint-enhancement/logs/                                                                        
│       output_dir: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-05-22_19-07-19                                       
│       work_dir: /home/gabriel/fingerprint-enhancement/src                                                                         
│                                                                                                                                   
├── extras
│   └── ignore_warnings: false                                                                                                      
│       enforce_tags: true                                                                                                          
│       print_config: true                                                                                                          
│                                                                                                                                   
├── task_name
│   └── train                                                                                                                       
├── tags
│   └── ['dev']                                                                                                                     
├── train
│   └── True                                                                                                                        
├── test
│   └── False                                                                                                                       
├── ckpt_path
│   └── /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-05-18_04-36-05/checkpoints/last.ckpt                             
└── seed
    └── None                                                                                                                        
[[36m2025-05-22 19:07:20,014[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.enhancer_train_datamodule.EnhancerTrainDataModule>[0m
[[36m2025-05-22 19:07:20,018[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.enhancer_module.EnhancerLitModule>[0m
[[36m2025-05-22 19:07:21,821[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2025-05-22 19:07:21,822[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-22 19:07:21,827[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2025-05-22 19:07:21,828[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-22 19:07:21,829[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-22 19:07:21,829[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2025-05-22 19:07:21,830[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.mlflow.MLFlowLogger>[0m
[[36m2025-05-22 19:07:21,834[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-22 19:07:21,889[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
[[36m2025-05-22 19:07:21,964[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
┏━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓
┃     ┃ Name                                 ┃ Type        ┃ Params ┃ Mode  ┃
┡━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩
│ 0   │ net                                  │ ResUNet     │ 30.3 M │ train │
│ 1   │ net.encoder                          │ Encoder     │ 19.5 M │ train │
│ 2   │ net.encoder.enc_blocks               │ ModuleList  │ 19.5 M │ train │
│ 3   │ net.encoder.enc_blocks.0             │ ResnetBlock │ 38.0 K │ train │
│ 4   │ net.encoder.enc_blocks.0.block1      │ Block       │    768 │ train │
│ 5   │ net.encoder.enc_blocks.0.block1.proj │ Conv2d      │    640 │ train │
│ 6   │ net.encoder.enc_blocks.0.block1.norm │ GroupNorm   │    128 │ train │
│ 7   │ net.encoder.enc_blocks.0.block1.act  │ SiLU        │      0 │ train │
│ 8   │ net.encoder.enc_blocks.0.block2      │ Block       │ 37.1 K │ train │
│ 9   │ net.encoder.enc_blocks.0.block2.proj │ Conv2d      │ 36.9 K │ train │
│ 10  │ net.encoder.enc_blocks.0.block2.norm │ GroupNorm   │    128 │ train │
│ 11  │ net.encoder.enc_blocks.0.block2.act  │ SiLU        │      0 │ train │
│ 12  │ net.encoder.enc_blocks.0.res_conv    │ Conv2d      │    128 │ train │
│ 13  │ net.encoder.enc_blocks.1             │ ResnetBlock │  230 K │ train │
│ 14  │ net.encoder.enc_blocks.1.block1      │ Block       │ 74.1 K │ train │
│ 15  │ net.encoder.enc_blocks.1.block1.proj │ Conv2d      │ 73.9 K │ train │
│ 16  │ net.encoder.enc_blocks.1.block1.norm │ GroupNorm   │    256 │ train │
│ 17  │ net.encoder.enc_blocks.1.block1.act  │ SiLU        │      0 │ train │
│ 18  │ net.encoder.enc_blocks.1.block2      │ Block       │  147 K │ train │
│ 19  │ net.encoder.enc_blocks.1.block2.proj │ Conv2d      │  147 K │ train │
│ 20  │ net.encoder.enc_blocks.1.block2.norm │ GroupNorm   │    256 │ train │
│ 21  │ net.encoder.enc_blocks.1.block2.act  │ SiLU        │      0 │ train │
│ 22  │ net.encoder.enc_blocks.1.res_conv    │ Conv2d      │  8.3 K │ train │
│ 23  │ net.encoder.enc_blocks.2             │ ResnetBlock │  919 K │ train │
│ 24  │ net.encoder.enc_blocks.2.block1      │ Block       │  295 K │ train │
│ 25  │ net.encoder.enc_blocks.2.block1.proj │ Conv2d      │  295 K │ train │
│ 26  │ net.encoder.enc_blocks.2.block1.norm │ GroupNorm   │    512 │ train │
│ 27  │ net.encoder.enc_blocks.2.block1.act  │ SiLU        │      0 │ train │
│ 28  │ net.encoder.enc_blocks.2.block2      │ Block       │  590 K │ train │
│ 29  │ net.encoder.enc_blocks.2.block2.proj │ Conv2d      │  590 K │ train │
│ 30  │ net.encoder.enc_blocks.2.block2.norm │ GroupNorm   │    512 │ train │
│ 31  │ net.encoder.enc_blocks.2.block2.act  │ SiLU        │      0 │ train │
│ 32  │ net.encoder.enc_blocks.2.res_conv    │ Conv2d      │ 33.0 K │ train │
│ 33  │ net.encoder.enc_blocks.3             │ ResnetBlock │  3.7 M │ train │
│ 34  │ net.encoder.enc_blocks.3.block1      │ Block       │  1.2 M │ train │
│ 35  │ net.encoder.enc_blocks.3.block1.proj │ Conv2d      │  1.2 M │ train │
│ 36  │ net.encoder.enc_blocks.3.block1.norm │ GroupNorm   │  1.0 K │ train │
│ 37  │ net.encoder.enc_blocks.3.block1.act  │ SiLU        │      0 │ train │
│ 38  │ net.encoder.enc_blocks.3.block2      │ Block       │  2.4 M │ train │
│ 39  │ net.encoder.enc_blocks.3.block2.proj │ Conv2d      │  2.4 M │ train │
│ 40  │ net.encoder.enc_blocks.3.block2.norm │ GroupNorm   │  1.0 K │ train │
│ 41  │ net.encoder.enc_blocks.3.block2.act  │ SiLU        │      0 │ train │
│ 42  │ net.encoder.enc_blocks.3.res_conv    │ Conv2d      │  131 K │ train │
│ 43  │ net.encoder.enc_blocks.4             │ ResnetBlock │ 14.7 M │ train │
│ 44  │ net.encoder.enc_blocks.4.block1      │ Block       │  4.7 M │ train │
│ 45  │ net.encoder.enc_blocks.4.block1.proj │ Conv2d      │  4.7 M │ train │
│ 46  │ net.encoder.enc_blocks.4.block1.norm │ GroupNorm   │  2.0 K │ train │
│ 47  │ net.encoder.enc_blocks.4.block1.act  │ SiLU        │      0 │ train │
│ 48  │ net.encoder.enc_blocks.4.block2      │ Block       │  9.4 M │ train │
│ 49  │ net.encoder.enc_blocks.4.block2.proj │ Conv2d      │  9.4 M │ train │
│ 50  │ net.encoder.enc_blocks.4.block2.norm │ GroupNorm   │  2.0 K │ train │
│ 51  │ net.encoder.enc_blocks.4.block2.act  │ SiLU        │      0 │ train │
│ 52  │ net.encoder.enc_blocks.4.res_conv    │ Conv2d      │  525 K │ train │
│ 53  │ net.encoder.pool                     │ MaxPool2d   │      0 │ train │
│ 54  │ net.decoder                          │ Decoder     │ 10.8 M │ train │
│ 55  │ net.decoder.upconvs                  │ ModuleList  │  697 K │ train │
│ 56  │ net.decoder.upconvs.0                │ Sequential  │  524 K │ train │
│ 57  │ net.decoder.upconvs.0.0              │ Upsample    │      0 │ train │
│ 58  │ net.decoder.upconvs.0.1              │ Conv2d      │  524 K │ train │
│ 59  │ net.decoder.upconvs.1                │ Sequential  │  131 K │ train │
│ 60  │ net.decoder.upconvs.1.0              │ Upsample    │      0 │ train │
│ 61  │ net.decoder.upconvs.1.1              │ Conv2d      │  131 K │ train │
│ 62  │ net.decoder.upconvs.2                │ Sequential  │ 32.9 K │ train │
│ 63  │ net.decoder.upconvs.2.0              │ Upsample    │      0 │ train │
│ 64  │ net.decoder.upconvs.2.1              │ Conv2d      │ 32.9 K │ train │
│ 65  │ net.decoder.upconvs.3                │ Sequential  │  8.3 K │ train │
│ 66  │ net.decoder.upconvs.3.0              │ Upsample    │      0 │ train │
│ 67  │ net.decoder.upconvs.3.1              │ Conv2d      │  8.3 K │ train │
│ 68  │ net.decoder.dec_blocks               │ ModuleList  │ 10.1 M │ train │
│ 69  │ net.decoder.dec_blocks.0             │ ResnetBlock │  7.6 M │ train │
│ 70  │ net.decoder.dec_blocks.0.block1      │ Block       │  4.7 M │ train │
│ 71  │ net.decoder.dec_blocks.0.block1.proj │ Conv2d      │  4.7 M │ train │
│ 72  │ net.decoder.dec_blocks.0.block1.norm │ GroupNorm   │  1.0 K │ train │
│ 73  │ net.decoder.dec_blocks.0.block1.act  │ SiLU        │      0 │ train │
│ 74  │ net.decoder.dec_blocks.0.block2      │ Block       │  2.4 M │ train │
│ 75  │ net.decoder.dec_blocks.0.block2.proj │ Conv2d      │  2.4 M │ train │
│ 76  │ net.decoder.dec_blocks.0.block2.norm │ GroupNorm   │  1.0 K │ train │
│ 77  │ net.decoder.dec_blocks.0.block2.act  │ SiLU        │      0 │ train │
│ 78  │ net.decoder.dec_blocks.0.res_conv    │ Conv2d      │  524 K │ train │
│ 79  │ net.decoder.dec_blocks.1             │ ResnetBlock │  1.9 M │ train │
│ 80  │ net.decoder.dec_blocks.1.block1      │ Block       │  1.2 M │ train │
│ 81  │ net.decoder.dec_blocks.1.block1.proj │ Conv2d      │  1.2 M │ train │
│ 82  │ net.decoder.dec_blocks.1.block1.norm │ GroupNorm   │    512 │ train │
│ 83  │ net.decoder.dec_blocks.1.block1.act  │ SiLU        │      0 │ train │
│ 84  │ net.decoder.dec_blocks.1.block2      │ Block       │  590 K │ train │
│ 85  │ net.decoder.dec_blocks.1.block2.proj │ Conv2d      │  590 K │ train │
│ 86  │ net.decoder.dec_blocks.1.block2.norm │ GroupNorm   │    512 │ train │
│ 87  │ net.decoder.dec_blocks.1.block2.act  │ SiLU        │      0 │ train │
│ 88  │ net.decoder.dec_blocks.1.res_conv    │ Conv2d      │  131 K │ train │
│ 89  │ net.decoder.dec_blocks.2             │ ResnetBlock │  476 K │ train │
│ 90  │ net.decoder.dec_blocks.2.block1      │ Block       │  295 K │ train │
│ 91  │ net.decoder.dec_blocks.2.block1.proj │ Conv2d      │  295 K │ train │
│ 92  │ net.decoder.dec_blocks.2.block1.norm │ GroupNorm   │    256 │ train │
│ 93  │ net.decoder.dec_blocks.2.block1.act  │ SiLU        │      0 │ train │
│ 94  │ net.decoder.dec_blocks.2.block2      │ Block       │  147 K │ train │
│ 95  │ net.decoder.dec_blocks.2.block2.proj │ Conv2d      │  147 K │ train │
│ 96  │ net.decoder.dec_blocks.2.block2.norm │ GroupNorm   │    256 │ train │
│ 97  │ net.decoder.dec_blocks.2.block2.act  │ SiLU        │      0 │ train │
│ 98  │ net.decoder.dec_blocks.2.res_conv    │ Conv2d      │ 32.9 K │ train │
│ 99  │ net.decoder.dec_blocks.3             │ ResnetBlock │  119 K │ train │
│ 100 │ net.decoder.dec_blocks.3.block1      │ Block       │ 73.9 K │ train │
│ 101 │ net.decoder.dec_blocks.3.block1.proj │ Conv2d      │ 73.8 K │ train │
│ 102 │ net.decoder.dec_blocks.3.block1.norm │ GroupNorm   │    128 │ train │
│ 103 │ net.decoder.dec_blocks.3.block1.act  │ SiLU        │      0 │ train │
│ 104 │ net.decoder.dec_blocks.3.block2      │ Block       │ 37.1 K │ train │
│ 105 │ net.decoder.dec_blocks.3.block2.proj │ Conv2d      │ 36.9 K │ train │
│ 106 │ net.decoder.dec_blocks.3.block2.norm │ GroupNorm   │    128 │ train │
│ 107 │ net.decoder.dec_blocks.3.block2.act  │ SiLU        │      0 │ train │
│ 108 │ net.decoder.dec_blocks.3.res_conv    │ Conv2d      │  8.3 K │ train │
│ 109 │ net.head                             │ Conv2d      │     65 │ train │
│ 110 │ criterion                            │ MyCriterion │      0 │ train │
│ 111 │ train_loss                           │ MeanMetric  │      0 │ train │
│ 112 │ val_loss                             │ MeanMetric  │      0 │ train │
│ 113 │ test_loss                            │ MeanMetric  │      0 │ train │
│ 114 │ val_loss_best                        │ MinMetric   │      0 │ train │
└─────┴──────────────────────────────────────┴─────────────┴────────┴───────┘
Trainable params: 30.3 M                                                                                                            
Non-trainable params: 0                                                                                                             
Total params: 30.3 M                                                                                                                
Total estimated model params size (MB): 121                                                                                         
Modules in train mode: 115                                                                                                          
Modules in eval mode: 0                                                                                                             
torch.Size([512, 512])
Epoch 100/299 ━━━                                      273/3163 0:01:00 • 0:10:33 4.57it/s v_num: 8ca4 train/loss_step: 320.044
torch.Size([512, 512])
torch.Size([512, 512])
torch.Size([512, 512])
[[36m2025-05-22 19:08:33,442[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Output dir: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-05-22_19-07-19[0m
